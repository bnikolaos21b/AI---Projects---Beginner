{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc3db98-8e8f-4c32-8b6b-7fb5a7a15a08",
   "metadata": {},
   "source": [
    "## House Prices Prediction with Advanced Regression Techniques\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This project involves predicting house prices using the **House Prices: Advanced Regression Techniques** dataset from Kaggle. We will utilize advanced regression models like **Ridge Regression**, **Lasso Regression**, and **ElasticNet** to improve generalization and reduce overfitting on high-dimensional data.\n",
    "\n",
    "By the end of this project, we will:\n",
    "- Preprocess the data, handle missing values, and encode categorical variables.\n",
    "- Implement Ridge, Lasso, and ElasticNet models to predict house prices.\n",
    "- Evaluate the performance of the models using metrics like **Mean Absolute Error (MAE)** and **R-squared**.\n",
    "\n",
    "Let's begin by loading the dataset and exploring its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4385c5a-a640-4232-a0e3-c027aff65879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41172d7c-068c-43df-932c-9f51423bb117",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section, we will preprocess the data by:\n",
    "1. Handling missing values.\n",
    "2. Encoding categorical variables.\n",
    "3. Scaling the numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a4b951-2a06-4083-9057-246e27e3ce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 285), (292, 285))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target (SalePrice) and features\n",
    "X = train_df.drop(columns=['SalePrice', 'Id'])\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data: Impute missing values and scale features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data: Impute missing values and encode categories\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine numerical and categorical transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply the transformations on the dataset\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Display the shape of the processed training and testing sets\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88dad3-9519-4a54-a36f-d33c2a464c36",
   "metadata": {},
   "source": [
    "## Ridge, Lasso, and ElasticNet Regression Models\n",
    "\n",
    "We will now implement three regularization techniques:\n",
    "1. **Ridge Regression (L2 Regularization)**: This penalizes large coefficients, reducing overfitting.\n",
    "2. **Lasso Regression (L1 Regularization)**: This drives some coefficients to zero, effectively selecting features.\n",
    "3. **ElasticNet Regression**: Combines L1 and L2 regularization for a balanced approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004103c1-dff9-4851-882c-fd85913bd879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - MAE: 19006.27520683145, R2: 0.8838815282935925\n",
      "Lasso - MAE: 18015.553395821902, R2: 0.8950852908903248\n",
      "ElasticNet - MAE: 18645.46557155519, R2: 0.8675482800896648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikos_pc/.local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:658: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 94725353591.82855, tolerance: 696659484.3571944\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries for models and evaluation\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize the models\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# Train the models\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "elasticnet_mae = mean_absolute_error(y_test, elasticnet_pred)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "elasticnet_r2 = r2_score(y_test, elasticnet_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Ridge - MAE: {ridge_mae}, R2: {ridge_r2}\")\n",
    "print(f\"Lasso - MAE: {lasso_mae}, R2: {lasso_r2}\")\n",
    "print(f\"ElasticNet - MAE: {elasticnet_mae}, R2: {elasticnet_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523042d8-0972-4a95-8905-5db464eb3639",
   "metadata": {},
   "source": [
    "## Improving Lasso and ElasticNet Convergence\n",
    "\n",
    "We will address the **ConvergenceWarning** seen in the previous results for **Lasso** and **ElasticNet**. The warning indicated that the model did not converge within the default number of iterations, which might have affected the performance of the models.\n",
    "\n",
    "### Adjustments:\n",
    "1. **Increase the number of iterations**: Lasso and ElasticNet models require more iterations to converge, especially when the dataset is complex.\n",
    "2. **Adjust the tolerance**: Lowering the tolerance for convergence will help the model find a more optimal solution.\n",
    "3. **Experiment with `alpha`**: We will also experiment with a larger `alpha` for ElasticNet to see if it improves the performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2be164-36b4-4f42-997e-fe163bd33f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - MAE: 19006.27520683145, R2: 0.8838815282935925\n",
      "Lasso - MAE: 18012.98620018198, R2: 0.895121527044661\n",
      "ElasticNet - MAE: 18645.466678960183, R2: 0.8675482666709546\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for the three models\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize the Ridge, Lasso, and ElasticNet models with tuned parameters\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "lasso_model = Lasso(alpha=0.1, max_iter=50000, tol=0.001)\n",
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=5000, tol=0.001)\n",
    "\n",
    "# Train the models\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "elasticnet_mae = mean_absolute_error(y_test, elasticnet_pred)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "elasticnet_r2 = r2_score(y_test, elasticnet_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Ridge - MAE: {ridge_mae}, R2: {ridge_r2}\")\n",
    "print(f\"Lasso - MAE: {lasso_mae}, R2: {lasso_r2}\")\n",
    "print(f\"ElasticNet - MAE: {elasticnet_mae}, R2: {elasticnet_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a90b1-0268-4c89-ac0b-4fbe379b14cd",
   "metadata": {},
   "source": [
    "After tuning the maximum iterations (`max_iter`) and adjusting tolerance (`tol`) for convergence, we obtained the following results for Ridge, Lasso, and ElasticNet:\n",
    "\n",
    "- **Ridge Regression**:\n",
    "  - Mean Absolute Error (MAE): *19,006*\n",
    "  - R-squared (RÂ²): *0.883*\n",
    "\n",
    "- **Lasso Regression**:\n",
    "  - Mean Absolute Error (MAE): *18,012*\n",
    "  - R-squared (RÂ²): *0.895*\n",
    "\n",
    "- **ElasticNet Regression**:\n",
    "  - Mean Absolute Error (MAE): *18,645*\n",
    "  - R-squared (RÂ²): *0.867*\n",
    "\n",
    "### Analysis\n",
    "\n",
    "- **Ridge Regression**:\n",
    "  Ridge regression, with an MAE of 19,006 and RÂ² of 0.883, performed well and reduces overfitting by applying L2 regularization. However, compared to Lasso, it did not perform as strongly on this dataset. \n",
    "\n",
    "- **Lasso Regression**:\n",
    "  Lasso performed the best, with an MAE of 18,012 and RÂ² of 0.895, indicating that it captures around **89.5%** of the variance in the house prices. The L1 regularization in Lasso likely led to better feature selection by driving irrelevant coefficients to zero.\n",
    "\n",
    "- **ElasticNet Regression**:\n",
    "  ElasticNet, with an MAE of 18,645 and RÂ² of 0.867, provided a balance between L1 and L2 regularization but still underperformed compared to Lasso. Fine-tuning the **l1_ratio** or **alpha** could improve its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcc88a-d5b2-4172-b472-d17835d2b03d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Conclusion:\n",
    "- **Lasso Regression** outperformed both Ridge and ElasticNet, achieving the lowest Mean Absolute Error (18,012) and highest RÂ² (0.895).\n",
    "- **Ridge Regression** provided a solid performance, reducing overfitting with L2 regularization, but with slightly higher error (MAE: 19,006).\n",
    "- **ElasticNet Regression** showed balanced regularization but underperformed compared to Lasso, with an MAE of 18,645 and RÂ² of 0.867.\n",
    "\n",
    "### Next Possible Steps:\n",
    "1. **Hyperparameter Tuning**: Further fine-tuning **alpha** and **l1_ratio** in ElasticNet may improve its performance.\n",
    "2. **Cross-Validation**: Perform cross-validation to ensure that the models generalize well to unseen data.\n",
    "3. **Feature Engineering**: Consider creating interaction features or addressing skewness in numerical variables to improve predictions.\n",
    "4. **Model Comparison**: Explore more advanced models like **Random Forest** or **XGBoost** to handle non-linear relationships in the dataset.\n",
    "\n",
    "By further tuning and exploring these models, we can improve accuracy and reduce the error margin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c8aa6-0a43-4b99-83ba-2861e8dc17ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
